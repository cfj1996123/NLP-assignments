{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"language model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1hXRXisRYNNxHDDOss27DrEIRrU_4fLc-","authorship_tag":"ABX9TyMgJ/d9b5Zpi7QBImQgThCG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"aH2Z7SRmeIMo","colab_type":"code","colab":{}},"source":["from os.path import join, exists\n","import os\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import numpy as np\n","\n","\n","class Dataset:\n","    def __init__(self, train_path, eval_path, test_path):\n","        self.word2idx = dict()\n","        self.idx2word = []\n","        # tokenize three files, and get its indexing tensors\n","        self.train = self.tokenize(train_path)\n","        self.eval = self.tokenize(eval_path)\n","        self.test = self.tokenize(test_path)\n","        self.num_words = len(self.idx2word)\n","\n","    def tokenize(self, path):\n","        assert exists(path), \"path is not valid.\"\n","        # construct word2idx and idx2word\n","        num_tokens = 0\n","        with open(path, \"r\") as f:\n","            for line in f:\n","                if len(line.strip()) == 0:\n","                    continue\n","                words = line.strip().split() + ['<end>']\n","                num_tokens += len(words)\n","                for word in words:\n","                    if word not in self.word2idx:\n","                        self.idx2word.append(word)\n","                        self.word2idx[word] = len(self.idx2word)-1\n","        # create a tensor of indices of all context\n","        with open(path, \"r\") as f:\n","            idx_tensor = torch.empty(num_tokens, dtype=torch.int64)\n","            token = 0\n","            for line in f:\n","                if len(line.strip()) == 0:\n","                    continue\n","                words = line.strip().split() + ['<end>']\n","                for word in words:\n","                    idx_tensor[token] = self.word2idx[word]\n","                    token += 1\n","\n","        return idx_tensor\n","\n","\n","class language_model(nn.Module):\n","    def __init__(self, num_words, embed_dim):\n","        super().__init__()\n","        self.embed = nn.Embedding(num_embeddings=num_words, embedding_dim=embed_dim) #size: (*) -> (*,embedding_dim)\n","        self.dropout1 = nn.Dropout(p=0.3)\n","        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=embed_dim, num_layers=2)\n","        self.linear = nn.Linear(in_features=embed_dim, out_features=num_words)\n","\n","\n","    def forward(self, x):\n","        '''\n","        :param x: tensor of indices of words, size (seq_len, batch_size)\n","        :return: tensor of probabilities for words at each time step\n","        '''\n","        output = self.embed(x)\n","        output = self.dropout1(output)\n","        output, _ = self.lstm(output) #size: (seq_len, batch_size, hidden_size)\n","        output = self.linear(output) #size: (seq_len, batch_size, num_words)\n","        return output\n","\n","\n","# parameters\n","batch_size = 5\n","seq_len = 10\n","embed_dim = 200\n","num_epoch = 100\n","snapshot_interval = 1\n","model_folder = \"model\"\n","checkpoint_path = \"model/model_epoch26\"\n","\n","base_lr = 0.001\n","train_path = \"drive/My Drive/Colab Notebooks/ptb_lm_small/train\"\n","eval_path = \"drive/My Drive/Colab Notebooks/ptb_lm_small/dev\"\n","test_path = \"drive/My Drive/Colab Notebooks/ptb_lm_small/test\"\n","\n","\n","def batchify(data, batch_size):\n","    nbatch = data.size(0) // batch_size\n","    # trim off data so that it can be divided by batch_size\n","    data = data.narrow(0, 0, batch_size*nbatch)\n","    data = data.view(batch_size, -1).t().contiguous() # size: (length per batch, batch_size)\n","    return data\n","\n","\n","def train(verbal=True):\n","    # check access to gpu\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # load dataset\n","    dataset = Dataset(train_path, eval_path, test_path)\n","    train = batchify(dataset.train, batch_size)\n","    eval = batchify(dataset.eval, batch_size)\n","    test = batchify(dataset.test, batch_size)\n","\n","    train = train.to(device)\n","    eval = eval.to(device)\n","    test = test.to(device)\n","\n","    # load model, optimizer and loss function\n","    os.makedirs(model_folder, exist_ok=True)\n","    net = language_model(num_words=dataset.num_words, embed_dim=embed_dim)\n","    net.train()\n","    net = net.to(device)\n","    optimizer = optim.Adam(net.parameters(), lr=base_lr, weight_decay=0.0001)\n","    entropy_loss = nn.CrossEntropyLoss(reduction=\"mean\")\n","\n","    if checkpoint_path != \"\":\n","        ## restore from checkpoint\n","        ckpt = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n","        net.load_state_dict(ckpt['model_params'])\n","        optimizer.load_state_dict(ckpt['optim_params'])\n","        epoch = ckpt['epoch']\n","    else:\n","        epoch = 0\n","\n","    train_loss = []\n","    eval_loss = []\n","    # code your training process here\n","    while epoch < num_epoch:\n","        loss_in_epoch = []\n","        iterator = range(0, train.size(0)-seq_len, seq_len)\n","        if verbal:\n","            iterator = tqdm(iterator)\n","        for start in iterator:\n","            # zero the accumulated gradients\n","            optimizer.zero_grad()\n","\n","            input = train[start:(start+seq_len), :]        #size: (seq_len, batch_size)\n","            truth = train[(start+1):(start+seq_len+1), :]  #size: (seq_len, batch_size)\n","            output = net.forward(input)                    #size: (seq_len, batch_size, num_words)\n","\n","            # compute training loss\n","            output = output.permute(0, 2, 1)               #size: (seq_len, num_words, batch_size)\n","            loss = entropy_loss(output, truth)\n","\n","            # do gradient descent\n","            loss.backward()\n","            nn.utils.clip_grad_norm(net.parameters(), 10.0)\n","            optimizer.step()\n","            loss_in_epoch.append(loss.item())\n","\n","            if verbal:\n","                description = 'epoch:{}, iteration:{}, current loss:{}, ' \\\n","                              'mean loss:{}'.format(epoch, start//seq_len, loss.item(), np.mean(loss_in_epoch))\n","                #baseline loss: -ln(1/num_words) = 8.37\n","                iterator.set_description(description)\n","\n","        train_loss.append(np.mean(loss_in_epoch))\n","        epoch += 1\n","\n","        # evaluation on eval set\n","        net.eval()\n","        eval_loss_in_epoch = []\n","        for start in range(0, eval.size(0) - seq_len, seq_len):\n","            input = eval[start:(start + seq_len), :]  # size: (seq_len, batch_size)\n","            truth = eval[(start + 1):(start + seq_len + 1), :]  # size: (seq_len, batch_size)\n","            output = net.forward(input)  # size: (seq_len, batch_size, num_words)\n","\n","            # compute training loss\n","            output = output.permute(0, 2, 1)  # size: (seq_len, num_words, batch_size)\n","            loss = entropy_loss(output, truth)\n","            eval_loss_in_epoch.append(loss.item())\n","\n","        eval_loss.append(np.mean(eval_loss_in_epoch))\n","        net.train()\n","\n","        # write averaged loss in this epoch into a file\n","        with open(\"loss.txt\", \"a+\") as f:\n","            f.write(\"epoch: {}, training loss: {}, eval loss:{}\\n\".\\\n","                    format(epoch,round(np.mean(loss_in_epoch),3), round(np.mean(eval_loss_in_epoch),3)))\n","\n","        print(\"epoch: {}, training loss: {}, eval loss:{}\".\\\n","                    format(epoch,round(np.mean(loss_in_epoch),3), round(np.mean(eval_loss_in_epoch),3)))\n","        \n","        # save model\n","        if epoch % snapshot_interval == 0 or epoch == num_epoch:\n","            ckpt_path = os.path.join(model_folder, 'model_epoch{}'.format(epoch))\n","            torch.save({'epoch': epoch,\n","                        'model_params': net.state_dict(),\n","                        'optim_params': optimizer.state_dict()},\n","                       ckpt_path\n","                       )\n","\n","\n","def test():\n","    # check access to gpu\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # load dataset\n","    dataset = Dataset(train_path, eval_path, test_path)\n","    test = batchify(dataset.test, batch_size)\n","    test = test.to(device)\n","\n","    net = language_model(num_words=dataset.num_words, embed_dim=embed_dim)\n","    net.eval()\n","    net = net.to(device)\n","    entropy_loss = nn.CrossEntropyLoss(reduction=\"mean\")\n","\n","    ## restore from checkpoint\n","    assert checkpoint_path!=\"\", \"invalid checkpoint!\"\n","    ckpt = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n","    net.load_state_dict(ckpt['model_params'])\n","    epoch = ckpt['epoch']\n","\n","    test_loss = []\n","    for start in range(0, test.size(0) - seq_len, seq_len):\n","        input = test[start:(start + seq_len), :]  # size: (seq_len, batch_size)\n","        truth = test[(start + 1):(start + seq_len + 1), :]  # size: (seq_len, batch_size)\n","        output = net.forward(input)  # size: (seq_len, batch_size, num_words)\n","\n","        # compute training loss\n","        output = output.permute(0, 2, 1)  # size: (seq_len, num_words, batch_size)\n","        loss = entropy_loss(output, truth)\n","        test_loss.append(loss.item())\n","\n","    print(\"test loss: {}\".format(np.mean(test_loss)))\n","\n","\n","train(verbal=False)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPEbMPa2xamx","colab_type":"code","outputId":"7a598782-e2bb-45f8-8bb4-6bcb81819382","executionInfo":{"status":"error","timestamp":1580680379072,"user_tz":480,"elapsed":885,"user":{"displayName":"Fengjie Chen","photoUrl":"","userId":"16362072093699323486"}},"colab":{"base_uri":"https://localhost:8080/","height":341}},"source":["from google.colab import files\n","# files.download('model.zip')\n","# files.download('loss.txt')"],"execution_count":20,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-24cb20228e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# files.download('model.zip')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: TypeError: Could not connect to the server."]}]},{"cell_type":"code","metadata":{"id":"woMEuWjgmRyZ","colab_type":"code","colab":{}},"source":["!zip -r model.zip model/"],"execution_count":0,"outputs":[]}]}